# 日志结构文件系统块访问深度预测

因为日志结构（Log-structure）文件块较为碎片化地分布在文件系统中，所以在文件的read上会带来比较多寻道操作，从而提升了延迟和开销。

而文件系统块访问的深度预测就可以很好地提前读取要访问的文件块，这样子就可以隐藏访问延迟。

本文的相关依据文献在[日志文件系统（Log-structured File Systems）读优化调研](http://blog.leanote.com/post/454858191@qq.com/日志结构文件系统（Log-structured-File-Systems）调研)这篇文章中。

## 1、获取trace

在访问深度的预测上，我们需要使用使用已有的访问历史记录。有一个网站可以让我们查到block级别的访问记录：

[SNIA IOTTA Repository BLOCK I/O TRACES](http://iotta.snia.org/tracetypes/3)

我们使用的是一个来自于微软的trace集，也就是`MSR-Cambridge`，我们使用里面的`mds_0`。得到的是一个csv文件，根据Readme的内容，这个csv文件一共分7列，每一列包含下面几个内容：

> The files are gzipped csv (comma-separated text) files. The fields in
> the csv are:
>
> Timestamp,Hostname,DiskNumber,Type,Offset,Size,ResponseTime
>
> Timestamp is the time the I/O was issued in "Windows filetime"
> Hostname is the hostname (should be the same as that in the trace file name)
> DiskNumber is the disknumber (should be the same as in the trace file name)
> Type is "Read" or "Write"
> Offset is the starting offset of the I/O in bytes from the start of the logical
> disk.
> Size is the transfer size of the I/O request in bytes.
> ResponseTime is the time taken by the I/O to complete, in Windows filetime
> units.

所以实际上所以我们先要编程对csv文件进行整理，我们只关注read类型，然后因为实际上在csv文件中只提供offset，我们需要设定一个块的大小来将这个csv文件中offset转化为一系列块号。

所以我们我们要写一个程序来来进行现有数据的整理。我们只需要一个序列，那就是操作的访问块号。

而在时序的问题上整个csv文件是按照整个从小到大的顺序排列的。所以就保持现有的顺序就可以了。

我们编写了`select-useful-data`，这个函（文件）可以将所有读的块号读取出来，写到一个新的`block_count`文件当中。

## 2、目的与动力

### 2.1、Linux现有的预测策略

这个章节我们要明确做这个工作的目的，要对比现有传统的预读策略为什么做得不够。

在IBM的技术网站[Linux 内核的文件 Cache 管理机制介绍](https://www.ibm.com/developerworks/cn/linux/l-cache/)中，我们可以看到新的Linux的读缓存管理：

> Linux内核中文件预读算法的具体过程是这样的：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面(不少于一个页面，通常是三个页面)，这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的group中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读group扩大一倍，并让底层文件系统读入group中剩下尚不在Cache中的文件数据块，这时的预读称为异步预读。无论第二次读请求是否命中，系统都要更新当前预读group的大小。此外，系统中定义了一个window，它包括前一次预读的group和本次预读的group。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读window中，这时继续进行异步预读并更新相应的window和group；第二种情况是所请求的页面处于预读window之外，这时系统就要进行同步预读并重置相应的window和group。图5是Linux内核预读机制的一个示意图，其中a是某次读操作之前的情况，b是读操作所请求页面不在window中的情况，而c是读操作所请求页面在window中的情况。

我们可以看到，实际上Linux对于文件顺序访问和随机访问是分开考虑的，所以实际上文件的随机访问是没有被处理的。而在Linux现有文件系统中，因为读的开销并不大（通过inode+bitmap就可以了）。所以这种死板的预读策略在顺序读取上有非常良好的表现，但是在随机读写上面实际上因为错误预测的开销比较低，所以在随机访问上的预测错误也是可以接受的。而因为随机访问实际上是比较常见的，所以这种开销就更小了。

### 2.2、顺序访问与随机访问

实际上因为现有文件系统在逻辑地址上面的顺序访问做的已经很不错了，所以对于顺序访问我么是有一定的必要保留的。这里就有一个问题，其实使用基于下文所提出的预测模型实际上也是可以做顺序预测的，但是为什么要将顺序和随机访问分开考虑这个是我考虑的比较多的。

下文我们要提出的所谓是深度预测模型是基于`用户访问模式`来进行预测的。但是预测手段在我看来实际上分为三类：**一种只是不基于用户访问记录**的，比如现有的Linux的算法（上文提及），完全不基于历史的访问记录，就是多顺序读几页，这种算法在顺序访问上有奇效，但是只考虑了单一使用场景。还有一种就是**只看一点点的记录**，比如在文件访问预测比较常用的LS（最近后继）算法，这种算法会根据上一次的同一个文件块的后继来决定这一次相同文件块的后继，这种算法将一定的用户访问模式考虑在内，对于用户的访问模式的变化也有一定的敏感度，对于短期的预测也有比较高的准确性（不管是随机还是顺序访问）。第三种就是非常**基于用户长久的使用记录，进行基于概率的预测**，比如对于用户的所有访问历史进行记录（比如马尔科夫模型）并且不断预测用户最为可能访问的节点，这种方式好访问在于能够比较好地进行长远的预测，但是对于用户访问模式的变化的响应性不足。

所以实际上我们可以看到，实际上看用户的访问历史看得越多的越有利于性能更个性化的长远预测；用户访问历史看得少的方式对于已经确定的某种模式的访问有奇效，并且对于模式的变化有比较好的相应，但是对于长远预测的响应性不足。

基于这种特点，我们需要将顺序和随机读取单独处理，因为逻辑地址的顺序读写是文件系统访问的主要问题，如果我们让基于概率的模型加入，那么这样的模型一定会将顺序访问的情况大量考虑在内，那么这种“过拟合”的风险将会导致在随机访问上的预测不足。

因为日志结构文件系统有比较大的读开销，所以为了保证预测的足够准确性，我们使用了多种预测模型的投票方式来提高预测的准确性。这里就涉及到一个权重的问题。因为不同的预测方法擅长的场景不同，所以我们应该在不同的场景下使用不同的权重。比如，如果Linux传统块预读策略多次成功，那就意味着当前是在连续读取的场景，那么这个时候我们就要大胆地增加预读的页数，并且增加Linux传统的预读策略在投票中的权重。如果Linux传统的预读策略多次失败，那么我们就认为这个是非连续读取的场景，那么这个时候我们就要增加另外两种类型的预测器的权重。

在随机访问的预测中，实际上我们也要考虑两个方面，分别是短期预测和长线预测。实际上，以LS（最近后继）为核心的算法在短期预测上有比较明显的优势，并且对于模式的变化反应比较机敏，而已markov为核心的算法在长远预测上有比较大的优势。所以在短预测与长预测上也要有权限上的区分。

### 2.3、基于LRU的缓存释放策略

在业内已经有较为成熟的缓存替换方案，即LRU策略（最近最少被使用），其实已经是一种考虑了用户使用模式的缓存算法，因为良好的准确性被使用。

## 3、预测模型的设计与实现

### 3.1、Page顺序预读策略模型

#### 3.1.1、Page顺序预读策略模型的设计

传统的预测方法，一开始预测3位，如果失败就一直预测三位，如果预测成功就顺序六位，并且在成功之后持续六位。

#### 3.1.2、Page顺序预读策略模型的实现

根据预测到那就三位，没有预测到那就六位的思路，我们非常轻易就可以给出实现。

```c
void page_predictor(long now_access, long *predictor_arr, int *size){
    if(predictor_arr == NULL){
        printf("predictor_arr必须在外部分配好空间、\n");
        return;
    }
    
    printf("开始进行预测，now_access = %ld\n", now_access);
    //开始预测，看看之前的预测是不是对的
    //查看之前的预测结果

    int i;

    //要返回的块编号的数量
    int return_num = 3;

    for(i = 0; i < MAX_HISTORY_ARR_SIZE; i++){
        //开始检查上一次预测的记录
        if(history_arr[i] == now_access){
            //这里说明这个块是上次预测到的
            return_num = 6;
            break;
        }
    }

    //初始化历史函数，等待下一次使用
    memset(&history_arr,0,MAX_HISTORY_ARR_SIZE*sizeof(long));

    //如果没有预测到，那就依旧返回三个，如果预测到了那就返回6个
    for(i = 0; i < return_num; i++){
        predictor_arr[i] = now_access + i + 1;
        //重新定义历史预测函数
        history_arr[i] = now_access + i + 1;
    }
    
    *size = return_num; 
    
}
```

我们在`MSR-Cambridge`中进行了测试，结果发现这个数据集是一个非常随机的数据集，无论是在1K还是4K下都几乎没有成功预读过。于是我们对其他的数据集做了预测。发现在`MSR-Cambridge`数据集中基本上都是随机读，这也说明了我们所做工作的必要性，实际上为微软服务器的场景中，实际上应该还是以随机访问为主的。





### 3.2、基于Noah的深度预测模型

#### 3.2.1、Noah预测的原理

LS是一种比较简单的预测方式，就是按照一个块号的上次的后继来预测这一次的后继。这是一种比较常见的预测方式，对于用户以及程序访问模式的变化有较好的响应度。但是对于深度预测的准确度就比较低了。

Noah是一种基于LS的预测方式，因为日志结构文件系统的读开销较大，所以对于读预测有比较大的开销，但是因为Noah只有在访问模式比较固定的时候才会做出预测，也就是说，只有连续两次出现相同后继的时候在预测的时候才会使用这个后继。

#### 3.2.2、Noah预测的实现

在Noah预测中我们需要维护两个东西，一个是当前块上一次访问的后继，还有一个当前块上一次预测的后继。

当一个节点的当前后继

## 4、预测模型的组合

实际上因为使用了多个预测器，实际上多个预测器的组合是个问题，所以我们需要为每个预测器都设定一个元数据。而在多个预测器下，我们需要知道“怎么才叫一个预测器预测对了”。也就是说当在上次预测深度的块IO上预测到了这个，那就认为这个块的预测是对的。这可以作为“连续访问”和“随机访问”的依据。





